{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 14:06:37.945864: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-17 14:06:40.318285: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_678825/1332832982.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 14:06:52.828125: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %whos\n",
    "# Load the .mat file\n",
    "file = h5py.File('Train.mat', 'r')\n",
    "\n",
    "# Extract datasets\n",
    "XTrain = file['X_normalized'][:]  # Shape: (200, 200,200, 1, n)\n",
    "YTrain = file['Y_img'][:]  # Shape: (n, 2)\n",
    "\n",
    "XTrain_permuted=np.transpose(XTrain,(0,3,4,2,1))\n",
    "YTrain_permuted=np.transpose(YTrain,(1,0))\n",
    "\n",
    "print(XTrain_permuted.shape)\n",
    "print(YTrain_permuted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the TensorBoard extension\n",
    "data = XTrain_permuted\n",
    "data = tf.squeeze(data, axis=4)\n",
    "print(data.shape)\n",
    "\n",
    "# Create the data augmentation generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.01,\n",
    "    height_shift_range=0.01,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data and YTrain_permuted are numpy arrays\n",
    "data = np.array(data)\n",
    "YTrain_permuted = np.array(YTrain_permuted)\n",
    "\n",
    "# Define the split ratio\n",
    "split_ratio = 0.2\n",
    "split_index = int((1 - split_ratio) * len(data))\n",
    "\n",
    "# Shuffling the dataset before splitting\n",
    "indices = np.random.permutation(len(data))\n",
    "train_indices = indices[:split_index]\n",
    "val_indices = indices[split_index:]\n",
    "\n",
    "train_data = data[train_indices]\n",
    "train_labels = YTrain_permuted[train_indices]\n",
    "val_data = data[val_indices]\n",
    "val_labels = YTrain_permuted[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import ConvNeXtTiny\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, Resizing,GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# Load pre-trained ConvNeXtTiny model without the top layer\n",
    "base_model = ConvNeXtTiny(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable=True\n",
    "\n",
    "# Create full model for fine-tunin\n",
    "model = Sequential()\n",
    "model.add(Resizing(224, 224, input_shape=(100,100,3)))\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128,activation='relu', kernel_regularizer=l2(1e-6)))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(1,kernel_regularizer=l2(1e-6)))\n",
    "\n",
    "\n",
    "# Use a small learning rate for fine-tuning\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=opt, loss='mse', metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "# Setup early stopping to prevent over-fitting.\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using the data augmentation generator\n",
    "import time\n",
    "start_time=time.time()\n",
    "history = model.fit(\n",
    "    datagen.flow(train_data, train_labels, batch_size=32),\n",
    "    epochs=100,\n",
    "    validation_data=(val_data, val_labels),\n",
    "    callbacks=[early_stopping,lr_reducer]\n",
    ")\n",
    "end_time=time.time()\n",
    "print(f\"Training time: {end_time-start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss and accuracy values\n",
    "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot loss on the left y-axis\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss', color='tab:blue')\n",
    "ax1.plot(history.history['loss'], label='Training Loss', color='tab:blue')\n",
    "if 'val_loss' in history.history:\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss', color='tab:cyan')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Title and layout\n",
    "plt.title('Model Loss and Accuracy')\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig('Convtiny.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_data = history.history\n",
    "import scipy.io\n",
    "scipy.io.savemat('Convtiny_history.mat', history_data)\n",
    "\n",
    "model.save('Convtiny.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.16.1",
   "language": "python",
   "name": "tensorflow2.16.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
